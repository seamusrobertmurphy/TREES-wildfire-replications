---
title: "Burn Area"
execute:
  echo: true
format:
  html:
    toc: true
    toc-location: right
    toc-depth: 3
    toc-title: "**On this page**"
    highlight-style: pygments
    page-layout: article

editor_options: 
  markdown: 
    wrap: 60
engine: knitr
bibliography: ../references/references.bib
csl: ../references/apa.csl
citeproc: true
---

## Overview {.unnumbered}

This chapter provides detailed workflows for detecting,
processing, and validating burned areas using MODIS MCD64A1
Collection 6.1 data within the Google Earth Engine (GEE)
platform. The methodology implements IPCC Tier 1
requirements while incorporating multi-source validation
using the `forestdata` package and alternative remote
sensing products.

### Environmental Setup {.unnumbered}

```{r}
#| warning: false
#| message: false
#| echo: true
#| comment: NA
easypackages::packages(
  "bslib", 
  "cols4all", "covr", "cowplot", 
  "dendextend", "digest","DiagrammeR","dtwclust", "downlit", 
  "e1071", "exactextractr","elevatr", 
  "FNN", "future", "forestdata",
  "gdalcubes", "gdalUtilities", "geojsonsf", "geos", "ggplot2", "ggstats", 
  "ggspatial", "ggmap", "ggplotify", "ggpubr", "ggrepel", "giscoR", 
  "hdf5r", "httr", "httr2", "htmltools",
  "jsonlite", 
  "kohonen", 
  "leaflet.providers", "leafem", "libgeos","luz","lwgeom", "leaflet", "leafgl",
  "mapedit", "mapview", "maptiles", "methods", "mgcv", 
  "ncdf4", "nnet", 
  "openxlsx", "parallel", "plotly", 
  "randomForest", "rasterVis", "raster", "Rcpp", "RcppArmadillo", 
  "RcppCensSpatial","rayshader", "RcppEigen", "RcppParallel", 
  "RColorBrewer", "reactable", "rgl", "rsconnect","RStoolbox", "rts", 
  "s2", "sf", "scales", "sits","spdep", "stars", "stringr","supercells", 
  "terra", "testthat", "tidyverse", "tidyterra","tools", 
  "tmap", "tmaptools", "terrainr", 
  "xgboost",
  prompt = F)
```

```{r}
#| warning: false
#| message: false
#| include: false
#| echo: false
#| comment: NA
options(repos = c(CRAN = "https://cloud.r-project.org"),
        htmltools.dir.version = FALSE, 
        htmltools.preserve.raw = FALSE
        )

knitr::opts_chunk$set(
  echo = TRUE, 
  message = FALSE, 
  warning = FALSE,
  error = FALSE, 
  comment = NA, 
  tidy.opts = list(width.cutoff = 60)
  ) 
sf::sf_use_s2(use_s2 = FALSE)
```

```{css, echo=FALSE, class.source = 'foldable'}
div.column {
    display: inline-block;
    vertical-align: top;
    width: 50%;
}

#TOC::before {
  content: "";
  display: block;
  height:200px;
  width: 200px;
  background-image: url('https://raw.githubusercontent.com/seamusrobertmurphy/map-templates/refs/heads/main/assets/outputs/01-site-map.png');
  background-size: contain;
  background-position: 50% 50%;
  padding-top: 80px !important;
  background-repeat: no-repeat;
}
```

## FAOSTAT Framework {#sec-ba-framework}

The FAOSTAT burned area workflow follows a pixel-to-country
aggregation approach:

1.  Pixel-level detection: Monthly MODIS MCD64A1 burned area
    product (500m resolution)
2.  Quality filtering: Retain only pixels with uncertainty
    \< 20%
3.  Temporal aggregation: Monthly observations \>\> annual
    burned area totals
4.  Spatial aggregation: Pixel sums \>\> country-level
    statistics via FAO GAUL boundaries
5.  Validation: Cross-comparison with alternative products
    and country reports

### Activity Data {#sec-ba-components}

Activity Data (A) in Equation 2.27 represents:

$$
A = \sum_{i=1}^{n} \text{Burned Area}_i \quad \text{(hectares)}
$$

Where:

-   $i$ = individual pixels detected as burned
-   $n$ = total number of burned pixels meeting quality
    criteria
-   Pixel area = 0.25 km² (500m × 500m) = 25 hectares at
    equator

Spatial Resolution Considerations:

-   Nominal 500m resolution
-   Actual ground distance varies by latitude:
    $d = 500 \times \cos(\text{latitude})$
-   Area calculations corrected using pixel-specific
    latitude

### Temporal Coverage {#sec-ba-temporal-coverage}

-   2001-2024: Direct MODIS MCD64A1 Collection 6.1
    observations
-   1996-2000: Earlier FAOSTAT estimates [@rossi2016faostat]
    using:
-   MODIS Collection 5 data - ATSR World Fire Atlas -
    TRMM/VIRS fire product
-   1990-1995: Gap-filled using averaged values: $$
    \text{BA}_{1990-1995} = \frac{1}{7} \sum_{y=1996}^{2002} \text{BA}_y
    $$

Rationale: Pre-MODIS era requires reconstruction; averaging
reduces bias from anomalous years.

------------------------------------------------------------

## Earth Engine: MCD64A1 {#sec-ba-gee-access}

-   Image Collection: `MODIS/061/MCD64A1`
-   Bands:
    -   `BurnDate`: Day of year (DOY) when burn detected
        (1-366, 0 = unburned)
    -   `Burn_Date_Uncertainty`: Percentage uncertainty
        (0-100%)
    -   `QA`: Quality assurance flags
    -   `First_Day`: First day of observation period
    -   `Last_Day`: Last day of observation period
-   Temporal Resolution: Monthly composites (2001-present)
-   Spatial Resolution: 500m
-   Projection: Sinusoidal (SR-ORG:6974)
-   Algorithm: Decision tree classifier using MODIS daily
    surface reflectance [@giglio2018collection]

```{r}
#| eval: false
#| label: gee-basic-access
#| code-summary: "Basic GEE access to MCD64A1"

library(rgee)
library(sf)
library(terra)

# Initialize Google Earth Engine
ee_Initialize(user = "your.email@domain.com")

# Define area of interest (example: Portugal)
aoi <- ee$Geometry$Rectangle(c(-9.5, 36.9, -6.2, 42.2))

# Load MCD64A1 collection
mcd64 <- ee$ImageCollection("MODIS/061/MCD64A1")

# Filter by location and time
burned_area <- mcd64$
  filterBounds(aoi)$
  filterDate("2023-01-01", "2023-12-31")

# Check collection size
print(paste("Images in collection:", burned_area$size()$getInfo()))
```

#### Multi-Criteria Filtering {#sec-ba-gee-advanced}

```{r}
#| eval: false
#| label: gee-advanced-filtering-a
#| code-summary: "Advanced filtering with quality criteria"

# Define quality filter function
filterQuality <- function(image) {
  # Extract bands
  burnDate <- image$select("BurnDate")
  uncertainty <- image$select("Burn_Date_Uncertainty")
  qa <- image$select("QA")
  
  # Create masks
  # 1. Valid burn date (1-366)
  validBurn <- burnDate$gt(0)$And(burnDate$lte(366))
  
  # 2. Uncertainty less than 20%
  lowUncertainty <- uncertainty$lt(20)
  
  # 3. QA indicates good quality (bit 0 = 0)
  goodQuality <- qa$bitwiseAnd(1)$eq(0)
  
  # Combine masks
  finalMask <- validBurn$And(lowUncertainty)$And(goodQuality)
  
  # Apply mask and return
  return(image$updateMask(finalMask))
}

# Apply quality filter to collection
mcd64_filtered <- burned_area$map(filterQuality)

# Verify filtering effect
print(paste("Filtered images:", mcd64_filtered$size()$getInfo()))
```

### Quality Assurance Flags {#sec-ba-qa-flags}

The QA band uses bit flags to encode quality information:

| Bit | Description         | Values                                |
|-----|---------------------|---------------------------------------|
| 0   | Land/Water          | 0=Land, 1=Water                       |
| 1-2 | Data Quality        | 00=Good, 01=Fair, 10=Poor, 11=No data |
| 3   | Direction of spread | 0=Unknown, 1=Known                    |

Recommended QA filtering:

```{r}
#| eval: false
#| label: qa-interpretation-a
#| code-summary: "QA flag interpretation"

# Extract quality information
extractQA <- function(image) {
  qa <- image$select("QA")
  
  # Bit 0: Land/Water
  landWater <- qa$bitwiseAnd(1)
  
  # Bits 1-2: Data quality (shift right 1, mask with 3)
  dataQuality <- qa$rightShift(1)$bitwiseAnd(3)
  
  # Add as separate bands
  return(image$
    addBands(landWater$rename("land_water"))$
    addBands(dataQuality$rename("data_quality"))
  )
}

# Apply QA extraction
mcd64_qa <- mcd64_filtered$map(extractQA)
```

------------------------------------------------------------

### FAOSTAT Quality Criteria {#sec-ba-faostat-criteria}

Primary criterion: Burn_Date_Uncertainty \< 20%

Rationale: MCD64A1 uncertainty estimates commission/omission
error probability

-   20% threshold balances omission (missing fires) vs.
    commission (false detections)
-   Giglio et al. (2018) validation shows:
    -   Uncertainty \< 20%: Commission \~15%, Omission \~30%
    -   Uncertainty \> 50%: Commission \~40%, Omission \~50%

Implementation:

```{r}
#| eval: false
#| label: faostat-filter
#| code-summary: "FAOSTAT quality filtering"

applyFAOSTATFilter <- function(image) {
  uncertainty <- image$select("Burn_Date_Uncertainty")
  burnDate <- image$select("BurnDate")
  
  # FAOSTAT criteria
  mask <- uncertainty$lt(20)$And(burnDate$gt(0))
  
  return(image$updateMask(mask))
}

# Apply to collection
mcd64_faostat <- burned_area$map(applyFAOSTATFilter)
```

### Uncertainty Quantification {#sec-ba-uncertainty-quant}

#### Sources of Uncertainty {.unnumbered}

1\. Detection Limitations:

-   Small fires (\< 500m): Often missed
-   Rapidly growing vegetation: Burn scar obscured within
    days
-   Dense canopy: Surface fires undetected
-   Cloud persistence: Reduces observation frequency

2\. Classification Errors:

-   Shadows misclassified as burned
-   Bare soil confusion with ash deposits
-   Agricultural harvesting vs. burning
-   Water level changes in wetlands

3\. Temporal Precision:

-   Burn date accuracy: ±8 days median
    [@giglio2018collection]
-   Multi-day fires: Only initial detection recorded
-   Slow-spreading fires: May span multiple pixels/dates

#### Validation Data {#sec-ba-validation-independent}

Active Fire Products (MCD14ML, MYD14):

```{r}
#| eval: false
#| label: active-fire-comparison
#| code-summary: "Compare with active fire detections"

# Load MODIS active fire product
activeFire <- ee$ImageCollection("MODIS/061/MOD14A1")$
  filterBounds(aoi)$
  filterDate("2023-01-01", "2023-12-31")$
  select("FireMask")

# Extract fire pixels (values 7-9 indicate fire)
firePixels <- activeFire$map(function(img) {
  return(img$gte(7)$selfMask())
})

# Reduce to annual maximum (any fire detection)
annualFireMask <- firePixels$max()

# Compare with burned area
burnedMask <- mcd64_faostat$
  select("BurnDate")$
  max()$
  gt(0)

# Calculate agreement
agreement <- burnedMask$And(annualFireMask)
baOnly <- burnedMask$And(annualFireMask$Not())
afOnly <- annualFireMask$And(burnedMask$Not())

# Export for analysis
Map$addLayer(agreement, list(palette = "green"), "Agreement")
Map$addLayer(baOnly, list(palette = "blue"), "BA only")
Map$addLayer(afOnly, list(palette = "red"), "AF only")
```

Landsat-based Products (30m resolution): Higher resolution
reference for validation, though less frequent temporal
coverage.

```{r}
#| eval: false
#| label: landsat-validation
#| code-summary: "Landsat burned area for validation"

# Example: Landsat 8 NBR differencing
# (Note: Requires custom burn severity calculation)

# Load pre-fire Landsat image
prefire <- ee$ImageCollection("LANDSAT/LC08/C02/T1_L2")$
  filterBounds(aoi)$
  filterDate("2023-06-01", "2023-06-30")$
  median()

# Load post-fire Landsat image  
postfire <- ee$ImageCollection("LANDSAT/LC08/C02/T1_L2")$
  filterBounds(aoi)$
  filterDate("2023-08-01", "2023-08-31")$
  median()

# Calculate NBR (Normalized Burn Ratio)
calculateNBR <- function(img) {
  nir <- img$select("SR_B5")
  swir <- img$select("SR_B7")
  nbr <- nir$subtract(swir)$divide(nir$add(swir))$rename("NBR")
  return(nbr)
}

nbr_pre <- calculateNBR(prefire)
nbr_post <- calculateNBR(postfire)

# Calculate dNBR (difference)
dnbr <- nbr_pre$subtract(nbr_post)

# Threshold for burned areas (dNBR > 0.1 indicates likely burn)
landsat_burn <- dnbr$gt(0.1)

# Resample MODIS to Landsat resolution for comparison
modis_burn_resampled <- burnedMask$
  reproject(crs = "EPSG:32629", scale = 30)  # Adjust CRS for AOI

# Calculate confusion matrix
# (Export both layers and analyze in R)
```

------------------------------------------------------------

## Temporal Aggregation {#sec-ba-temporal-agg}

### Annualization {#sec-ba-monthly-annual}

```{r}
#| eval: false
#| label: annual-summation
#| code-summary: "Aggregate monthly burned area to annual"

# Function to create binary burned/unburned
binaryBurn <- function(image) {
  burned <- image$select("BurnDate")$gt(0)
  return(burned$
    rename("burned")$
    copyProperties(image, list("system:time_start"))
  )
}

# Convert to binary
mcd64_binary <- mcd64_faostat$map(binaryBurn)

# Reduce to annual maximum (any pixel burned at any time = burned)
annual_burned_2023 <- mcd64_binary$
  filterDate("2023-01-01", "2023-12-31")$
  max()$
  selfMask()

# Visualize
vis_params <- list(
  palette = c("yellow", "orange", "red"),
  min = 0,
  max = 1
)

Map$centerObject(aoi, zoom = 7)
Map$addLayer(annual_burned_2023, vis_params, "2023 Burned Area")
```

#### Multiple Burns Accounting {#sec-ba-multiple-burns}

::: {.callout-caution collapse="false"}
## Challenge: A pixel can burn multiple times per year.

FAOSTAT approach: Count pixel as burned once per year
(conservative).

Alternative: Track number of burns per pixel:
:::

```{r}
#| eval: false
#| label: multiple-burns
#| code-summary: "Track multiple burns per pixel"

# Count number of times each pixel burned
burnCount <- mcd64_binary$
  filterDate("2023-01-01", "2023-12-31")$
  sum()$
  rename("burn_count")

# Classify burn frequency
frequency_classes <- burnCount$
  where(burnCount$eq(0), 0)$  # Unburned
  where(burnCount$eq(1), 1)$  # Burned once
  where(burnCount$gte(2), 2)  # Burned multiple times

Map$addLayer(
  frequency_classes, 
  list(min = 0, max = 2, palette = c("white", "orange", "red")),
  "Burn Frequency"
)

# For IPCC Tier 1: Use binary (burned/not burned)
# For Tier 2+: Consider multiple burns in fuel consumption
```

### Time Series Construction {#sec-ba-timeseries}

#### Burned Area Stack {#sec-ba-annual-stack}

```{r}
#| eval: false
#| label: timeseries-stack
#| code-summary: "Create multi-year burned area stack"

# Define years of interest
years <- seq(2001, 2023, 1)

# Function to get annual burned area for a given year
getAnnualBurn <- function(year) {
  # Filter collection to year
  year_collection <- mcd64_faostat$
    filter(ee$Filter$calendarRange(year, year, "year"))
  
  # Convert to binary and reduce to max
  annual_burn <- year_collection$
    map(binaryBurn)$
    max()$
    unmask(0)  # Fill unburned pixels with 0
  
  # Set year property
  return(annual_burn$
    set("year", year)$
    set("system:time_start", ee$Date$fromYMD(year, 1, 1)$millis())
  )
}

# Create collection of annual burned areas
annual_collection <- ee$ImageCollection(
  lapply(years, function(y) getAnnualBurn(y))
)

# Example: Calculate total area burned per year
# (Will aggregate spatially in next section)
```

#### Trend Analysis {#sec-ba-trends}

```{r}
#| eval: false
#| label: trend-analysis
#| code-summary: "Analyze temporal trends in burned area"

# Linear trend over time series
# Note: This is a simplified pixel-wise trend
# For country-level trends, aggregate first (see next section)

# Add year band to each image
addYearBand <- function(image) {
  year <- ee$Number(image$get("year"))
  yearBand <- ee$Image$constant(year)$toFloat()$rename("year")
  return(image$addBands(yearBand))
}

annual_with_year <- annual_collection$map(addYearBand)

# Linear regression: burned ~ year
regression <- annual_with_year$
  select(c("year", "burned"))$
  reduce(ee$Reducer$linearFit())

# Extract slope (trend)
trend <- regression$select("scale")

# Visualize increasing/decreasing trends
trend_vis <- list(
  min = -0.05,
  max = 0.05,
  palette = c("blue", "white", "red")
)

Map$addLayer(trend, trend_vis, "Burn Trend (2001-2023)")
```

------------------------------------------------------------

## Spatial Aggregation {#sec-ba-spatial-agg}

### Country-Level Summaries {#sec-ba-country-sum}

#### Using FAO GAUL Boundaries {#sec-ba-gaul}

```{r}
#| eval: false
#| label: gaul-aggregation
#| code-summary: "Aggregate burned area by country"

# Load FAO GAUL country boundaries (Admin Level 0)
countries <- ee$FeatureCollection("FAO/GAUL/2015/level0")

# Select specific country (example: Portugal)
portugal <- countries$filter(ee$Filter$eq("ADM0_NAME", "Portugal"))

# Calculate burned area for 2023
burned_2023 <- annual_burned_2023

# Zonal statistics: sum of burned pixels
burnedArea_ha <- burned_2023$
  multiply(ee$Image$pixelArea()$divide(10000))$  # Convert m² to hectares
  reduceRegions(
    collection = portugal,
    reducer = ee$Reducer$sum(),
    scale = 500,
    crs = "SR-ORG:6974"  # MCD64A1 native projection
  )

# Extract result
result <- burnedArea_ha$getInfo()
print(paste("Burned area (ha):", result$features[[1]]$properties$sum))
```

#### Batch Processing for All Countries {#sec-ba-batch}

```{r}
#| eval: false
#| label: batch-countries
#| code-summary: "Process all countries efficiently"

# Function to calculate burned area for a single country
calculateCountryBA <- function(country_name, year) {
  # Filter country
  country <- countries$filter(ee$Filter$eq("ADM0_NAME", country_name))
  
  # Get annual burned area
  annual_burn <- getAnnualBurn(year)
  
  # Convert to area (hectares)
  burn_area_ha <- annual_burn$
    multiply(ee$Image$pixelArea()$divide(10000))
  
  # Reduce by region
  stats <- burn_area_ha$reduceRegions(
    collection = country,
    reducer = ee$Reducer$sum(),
    scale = 500
  )
  
  # Add metadata
  return(stats$map(function(f) {
    return(f$
      set("year", year)$
      set("country", country_name)
  }))
}

# Process multiple countries and years
country_list <- c("Portugal", "Spain", "France", "Greece")
year_list <- c(2020, 2021, 2022, 2023)

# Create tasks (run in parallel in GEE)
# Note: For production, export to Google Drive or Asset

for (country in country_list) {
  for (year in year_list) {
    result <- calculateCountryBA(country, year)
    
    # Export task
    task <- ee$batch$Export$table$toDrive(
      collection = result,
      description = paste0(country, "_", year, "_BA"),
      folder = "IPCC_Fire_Emissions",
      fileFormat = "CSV"
    )
    
    task$start()
    print(paste("Started task:", country, year))
  }
}
```

### Sub-National Aggregation {#sec-ba-subnational}

```{r}
#| eval: false
#| label: subnational-aggregation
#| code-summary: "Admin level 1 and 2 aggregation"

# Load Admin Level 1 (provinces/states)
admin1 <- ee$FeatureCollection("FAO/GAUL/2015/level1")

# Filter to country
portugal_admin1 <- admin1$filter(ee$Filter$eq("ADM0_NAME", "Portugal"))

# Calculate burned area by province
provincial_BA <- burned_2023$
  multiply(ee$Image$pixelArea()$divide(10000))$
  reduceRegions(
    collection = portugal_admin1,
    reducer = ee$Reducer$sum(),
    scale = 500
  )

# Convert to sf object for analysis in R
provincial_BA_sf <- ee_as_sf(provincial_BA)

# Visualize
library(ggplot2)
ggplot(provincial_BA_sf) +
  geom_sf(aes(fill = sum)) +
  scale_fill_viridis_c(name = "Burned Area (ha)") +
  labs(title = "Burned Area by Province - Portugal 2023") +
  theme_minimal()
```

### Area Calculation Corrections {#sec-ba-area-correction}

Latitude correction for pixel area:

```{r}
#| eval: false
#| label: area-correction
#| code-summary: "Correct pixel area for latitude"

# Standard approach: Use ee.Image.pixelArea()
# This automatically accounts for latitude

# Manual calculation (for understanding):
calculatePixelArea <- function(image) {
  # Get latitude for each pixel
  lat <- ee$Image$pixelLonLat()$select("latitude")
  
  # Convert to radians
  lat_rad <- lat$multiply(pi / 180)
  
  # Pixel height (constant in sinusoidal projection)
  pixel_height_m <- 463.3127  # meters at equator for 500m product
  
  # Pixel width varies with latitude
  pixel_width_m <- pixel_height_m$multiply(lat_rad$cos())
  
  # Area in m²
  pixel_area_m2 <- pixel_height_m$multiply(pixel_width_m)
  
  return(pixel_area_m2)
}

# Compare with built-in function
pixel_area_builtin <- ee$Image$pixelArea()
pixel_area_manual <- calculatePixelArea()

# They should match (built-in is more accurate)
```

------------------------------------------------------------

## Multi-Source Validation {#sec-ba-validation}

### GLAD Comparison {#sec-ba-glad-comparison}

Using `forestdata` package for complementary validation:

```{r}
#| eval: false
#| label: glad-validation
#| code-summary: "Validate with GLAD land cover change"

library(forestdata)
library(terra)
library(sf)

# Define area of interest in R
portugal_sf <- st_read("path/to/portugal_boundary.gpkg")
portugal_bbox <- st_bbox(portugal_sf)

# Download GLAD land cover change (2000-2020)
glad_change <- fd_forest_glad(
  lon = mean(c(portugal_bbox["xmin"], portugal_bbox["xmax"])),
  lat = mean(c(portugal_bbox["ymin"], portugal_bbox["ymax"])),
  model = "landcover-change",
  year = 2020  # Ignored for change product
)

# Download MODIS burned area from GEE (from previous sections)
# Export annual_burned_2023 to R
modis_burn_2023 <- ee_as_rast(
  annual_burned_2023,
  region = aoi,
  scale = 500
)

# Resample GLAD to MODIS resolution for comparison
glad_change_500m <- resample(glad_change, modis_burn_2023, method = "near")

# Crop to same extent
glad_crop <- crop(glad_change_500m, modis_burn_2023)
modis_crop <- crop(modis_burn_2023, glad_change_500m)

# Analyze agreement
# GLAD change codes: Extract relevant change types
# (Consult GLAD documentation for specific codes)

# Example: Extract forest loss pixels
glad_forest_loss <- glad_crop == 2  # Adjust code based on GLAD legend

# Calculate confusion matrix
library(caret)
confusion <- confusionMatrix(
  data = as.factor(as.vector(modis_crop)),
  reference = as.factor(as.vector(glad_forest_loss))
)

print(confusion)
```

### ESRI-LULC Comparison {#sec-ba-esri-validation}

```{r}
#| eval: false
#| label: esri-validation
#| code-summary: "Validate with ESRI 10m land cover"

library(forestdata)

# Portugal is in UTM zone 29N
esri_2022 <- fd_landcover_esri(utm_code = "29N", year = 2022)
esri_2023 <- fd_landcover_esri(utm_code = "29N", year = 2023)

# Detect land cover changes between years
esri_change <- esri_2023 - esri_2022

# Focus on transitions to "bare ground" class (potential fire)
# (Check ESRI legend for bare ground class code)
bare_ground_code <- 8  # Example - verify from ESRI documentation

esri_to_bare <- (esri_2022 != bare_ground_code) & 
                (esri_2023 == bare_ground_code)

# Resample to MODIS resolution
esri_change_500m <- aggregate(
  esri_to_bare, 
  fact = 50,  # 10m to 500m = factor of 50
  fun = mean  # Proportion of 10m pixels that changed
)

# Overlay with MODIS burned area
# High agreement expected in fire-affected forests
# Disagreement may indicate:
#   - MODIS missed small fires (ESRI detected)
#   - ESRI detected non-fire disturbances (logging, etc.)
```

### Country Data Comparison {#sec-ba-country-reports}

```{r}
#| eval: false
#| label: country-comparison
#| code-summary: "Compare with UNFCCC country reports"

# Example: Load country-reported burned area
# (Would typically come from UNFCCC National Inventory Reports)

country_reported <- data.frame(
  year = 2020:2023,
  reported_ba_ha = c(45000, 52000, 38000, 61000),  # Example data
  source = "National Forest Inventory"
)

# Calculate FAOSTAT burned area from GEE results
# (Assuming you've exported multi-year results)
faostat_ba <- data.frame(
  year = 2020:2023,
  faostat_ba_ha = c(42000, 49000, 36000, 58000)  # From GEE exports
)

# Merge and compare
comparison <- merge(country_reported, faostat_ba, by = "year")
comparison$difference_ha <- comparison$reported_ba_ha - comparison$faostat_ba_ha
comparison$percent_diff <- (comparison$difference_ha / comparison$reported_ba_ha) * 100

# Visualize
library(ggplot2)
ggplot(comparison, aes(x = year)) +
  geom_line(aes(y = reported_ba_ha, color = "Country Reported"), linewidth = 1) +
  geom_line(aes(y = faostat_ba_ha, color = "FAOSTAT"), linewidth = 1) +
  geom_point(aes(y = reported_ba_ha, color = "Country Reported"), size = 3) +
  geom_point(aes(y = faostat_ba_ha, color = "FAOSTAT"), size = 3) +
  scale_color_manual(values = c("Country Reported" = "blue", "FAOSTAT" = "red")) +
  labs(
    title = "Burned Area Comparison: Country Reports vs. FAOSTAT",
    subtitle = "Portugal 2020-2023",
    x = "Year",
    y = "Burned Area (hectares)",
    color = "Source"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")

# Statistical assessment
cor_test <- cor.test(comparison$reported_ba_ha, comparison$faostat_ba_ha)
print(paste("Correlation:", round(cor_test$estimate, 3)))
print(paste("P-value:", cor_test$p.value))
```

------------------------------------------------------------

## Uncertainty Reporting {#sec-ba-uncertainty-assessment}

### Quantifying Total Uncertainty {#sec-ba-total-uncertainty}

Following IPCC guidelines, uncertainty in burned area
activity data combines:

$$
U_{total}^2 = U_{detection}^2 + U_{classification}^2 + U_{area}^2
$$

Where:

-   $U_{detection}$ = Omission/commission errors in fire
    detection
-   $U_{classification}$ = Land cover misclassification
    affecting fire-prone area
-   $U_{area}$ = Geometric/projection errors in area
    calculation

Typical values for MODIS MCD64A1:

-   Detection uncertainty: ±25-35% (varies by biome)
-   Classification uncertainty: ±10-15% (from MCD12Q1
    validation)
-   Area uncertainty: ±2-5% (projection and edge effects)

Combined uncertainty: Approximately ±30% for global Tier 1
applications

### Sensitivity Analysis {#sec-ba-sensitivity}

```{r}
#| eval: false
#| label: sensitivity-analysis
#| code-summary: "Assess sensitivity to quality threshold"

# Test multiple uncertainty thresholds
thresholds <- c(10, 15, 20, 25, 30)

sensitivity_results <- data.frame(
  threshold = numeric(),
  burned_area_ha = numeric(),
  pixel_count = numeric()
)

for (thresh in thresholds) {
  # Apply threshold
  filtered <- mcd64$
    filterDate("2023-01-01", "2023-12-31")$
    map(function(img) {
      mask <- img$select("Burn_Date_Uncertainty")$lt(thresh)$
        And(img$select("BurnDate")$gt(0))
      return(img$updateMask(mask))
    })
  
  # Calculate burned area
  result <- filtered$
    select("BurnDate")$
    max()$
    multiply(ee$Image$pixelArea()$divide(10000))$
    reduceRegion(
      reducer = ee$Reducer$sum(),
      geometry = aoi,
      scale = 500,
      maxPixels = 1e9
    )
  
  # Store results
  sensitivity_results <- rbind(
    sensitivity_results,
    data.frame(
      threshold = thresh,
      burned_area_ha = result$getInfo()$BurnDate,
      pixel_count = NA  # Could calculate separately
    )
  )
}

# Visualize sensitivity
ggplot(sensitivity_results, aes(x = threshold, y = burned_area_ha)) +
  geom_line(linewidth = 1, color = "darkred") +
  geom_point(size = 3, color = "darkred") +
  geom_vline(xintercept = 20, linetype = "dashed", color = "blue") +
  annotate("text", x = 20, y = max(sensitivity_results$burned_area_ha) * 0.9,
           label = "FAOSTAT threshold", hjust = -0.1) +
  labs(
    title = "Sensitivity of Burned Area to Quality Threshold",
    x = "Uncertainty Threshold (%)",
    y = "Burned Area (hectares)"
  ) +
  theme_minimal()
```

### Documenting Uncertainty for NGHGI {#sec-ba-nghgi-uncertainty}

Required documentation for Tier 1:

1.  Data source and version: MODIS MCD64A1 Collection 6.1
2.  Quality criteria applied: Uncertainty \< 20%
3.  Spatial coverage: Percentage of country with valid
    observations
4.  Temporal coverage: Months with cloud-free observations
5.  Estimated uncertainty: ±30% (or country-specific if
    available)
6.  Validation results: Comparison with independent data
    sources

Example uncertainty table for NGHGI report:

```{r}
#| eval: false
#| label: uncertainty-table
#| echo: false

library(knitr)

uncertainty_table <- data.frame(
  Source = c("Satellite detection", "Land cover classification", 
             "Area calculation", "Total (quadrature)"),
  Uncertainty = c("±30%", "±15%", "±5%", "±34%"),
  Method = c(
    "MCD64A1 validation (Giglio et al. 2018)",
    "MCD12Q1 accuracy assessment",
    "Projection error analysis",
    "IPCC Equation 3.1"
  )
)

kable(
  uncertainty_table,
  caption = "Uncertainty Components in Burned Area Activity Data (Tier 1)",
  align = c("l", "c", "l")
)
```

------------------------------------------------------------

## Reproducible Workflow {#sec-ba-workflow-summary}

### Complete Processing Pipeline {#sec-ba-pipeline}

```{r}
#| eval: false
#| label: complete-pipeline
#| code-summary: "End-to-end burned area processing"

# ============================================================
# IPCC Tier 1 Burned Area Processing Pipeline
# MODIS MCD64A1 Collection 6.1
# ============================================================

library(rgee)
library(sf)
library(terra)
library(tidyverse)

# Initialize
ee_Initialize()

# 1. DEFINE PARAMETERS ----------------------------------------
country_name <- "Portugal"
year_start <- 2020
year_end <- 2023
uncertainty_threshold <- 20

# 2. LOAD SPATIAL DATA ----------------------------------------
# Country boundary
countries <- ee$FeatureCollection("FAO/GAUL/2015/level0")
aoi <- countries$filter(ee$Filter$eq("ADM0_NAME", country_name))

# Burned area collection
mcd64 <- ee$ImageCollection("MODIS/061/MCD64A1")

# 3. QUALITY FILTERING ----------------------------------------
filterQuality <- function(image) {
  uncertainty <- image$select("Burn_Date_Uncertainty")
  burnDate <- image$select("BurnDate")
  mask <- uncertainty$lt(uncertainty_threshold)$And(burnDate$gt(0))
  return(image$updateMask(mask))
}

# 4. TEMPORAL AGGREGATION -------------------------------------
getAnnualBurn <- function(year) {
  annual <- mcd64$
    filter(ee$Filter$calendarRange(year, year, "year"))$
    filterBounds(aoi)$
    map(filterQuality)$
    select("BurnDate")$
    max()$
    gt(0)$
    selfMask()
  
  return(annual$
    set("year", year)$
    set("system:time_start", ee$Date$fromYMD(year, 1, 1)$millis()))
}

years <- seq(year_start, year_end, 1)
annual_collection <- ee$ImageCollection(lapply(years, getAnnualBurn))

# 5. SPATIAL AGGREGATION --------------------------------------
calculateBA <- function(image) {
  year <- image$get("year")
  area_ha <- image$
    multiply(ee$Image$pixelArea()$divide(10000))$
    reduceRegion(
      reducer = ee$Reducer$sum(),
      geometry = aoi,
      scale = 500,
      maxPixels = 1e9
    )
  
  return(ee$Feature(NULL, list(
    year = year,
    country = country_name,
    burned_area_ha = area_ha$get("BurnDate")
  ))
}

results <- annual_collection$map(calculateBA)

# 6. EXPORT RESULTS -------------------------------------------
# To Google Drive
task <- ee$batch$Export$table$toDrive(
  collection = results,
  description = paste0(country_name, "_BA_", year_start, "_", year_end),
  folder = "IPCC_Fire_Emissions",
  fileFormat = "CSV"
)

task$start()
print(paste("Export started:", task$id))

# Or get directly in R (for small areas)
results_df <- ee_as_sf(results) %>%
  st_drop_geometry() %>%
  as.data.frame()

print(results_df)

# 7. VISUALIZATION --------------------------------------------
ggplot(results_df, aes(x = year, y = burned_area_ha)) +
  geom_line(color = "darkred", linewidth = 1) +
  geom_point(color = "darkred", size = 3) +
  labs(
    title = paste("Annual Burned Area -", country_name),
    subtitle = paste("MODIS MCD64A1 Collection 6.1 |", year_start, "-", year_end),
    x = "Year",
    y = "Burned Area (hectares)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 10, color = "gray40")
  )
```

### Data Export Formats {#sec-ba-export-formats}

For NGHGI Reporting:

```{r}
#| eval: false
#| label: export-nghgi
#| code-summary: "Export in NGHGI-compatible format"

# Create IPCC-compatible output table
nghgi_output <- results_df %>%
  mutate(
    Category = "4.C Forest Land",
    Subcategory = "Fires on Forest Land",
    Activity_Data_Unit = "ha",
    Data_Source = "MODIS MCD64A1 Collection 6.1",
    Quality_Tier = "Tier 1",
    Uncertainty_Percent = 30
  ) %>%
  rename(
    Year = year,
    Country = country,
    Burned_Area_ha = burned_area_ha
  )

# Export
write.csv(
  nghgi_output,
  file = paste0(country_name, "_BurnedArea_NGHGI_", Sys.Date(), ".csv"),
  row.names = FALSE
)
```

### Quality Control Checklist {#sec-ba-qc-checklist}

Pre-processing:

-   GEE authentication successful
-   AOI geometry valid (no self-intersections)
-   Date range covers complete years
-   Image collection not empty

Processing:

-   Quality filter applied (uncertainty \< 20%)
-   Temporal aggregation complete (12 months per year)
-   Spatial aggregation uses correct boundaries
    [@eurostatGeographicInformationSystem2025]
-   Area calculation accounts for projection

Post-processing:

-   No missing years in time series
-   Burned area values reasonable (order of magnitude check)
-   Comparison with previous estimates (if available)
-   Validation with independent data
-   Uncertainty quantified and documented

Reporting:

-   Data source and version documented
-   Methods transparent and reproducible
-   Code archived in version control
-   Results exported in standard format
-   Metadata complete (CRS, resolution, quality flags)

------------------------------------------------------------
